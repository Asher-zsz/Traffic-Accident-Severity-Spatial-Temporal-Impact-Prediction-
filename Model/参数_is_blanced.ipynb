{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def log_loss(y_true, y_pred, pos_weight=None):\n",
    "    is_positive = y_true == 1#is_positive的mask\n",
    "    loss = np.zeros_like(y_pred)# loss初始化为0,维度与y_pred相同\n",
    "    loss[is_positive] = -np.log(y_pred[is_positive])\n",
    "    loss[~is_positive] = -np.log(1.0 - y_pred[~is_positive])\n",
    "    if pos_weight:\n",
    "        weights = np.ones_like(y_pred)\n",
    "        weights[is_positive] = pos_weight\n",
    "        return np.average(loss, weights=weights)\n",
    "    else:\n",
    "        return np.average(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([          0,           0, -2147483648, -2147483648,           0,\n",
       "                 0,           0,           0,           0,           0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=np.array([0, 1, 0, 1, 1, 0, 0, 0, 1, 0])\n",
    "y_true=np.array([0, 1, 1, 0, 1, 0, 0, 0, 1, 0])\n",
    "is_positive = y_true == 1\n",
    "loss = np.zeros_like(y_pred)# loss初始化为0\n",
    "loss[is_positive] = -np.log(y_pred[is_positive])\n",
    "loss[~is_positive] = -np.log(1.0 - y_pred[~is_positive])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss[is_positive] = -np.log(y_pred[is_positive])\n",
    "loss[~is_positive] = -np.log(1.0 - y_pred[~is_positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data, positive: 349, negative: 3151, positive ratio: 0.10\n",
      "Test data, positive: 151, negative: 1349, positive ratio: 0.10\n",
      "[LightGBM] [Info] Number of positive: 349, number of negative: 3151\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.099714 -> initscore=-2.200403\n",
      "[LightGBM] [Info] Start training from score -2.200403\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\ttrain's binary_logloss: 0.232839\ttest's binary_logloss: 0.236435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\ttrain's binary_logloss: 0.19447\ttest's binary_logloss: 0.199018\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\ttrain's binary_logloss: 0.167684\ttest's binary_logloss: 0.172805\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\ttrain's binary_logloss: 0.147018\ttest's binary_logloss: 0.152877\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\ttrain's binary_logloss: 0.129909\ttest's binary_logloss: 0.13641\n",
      "[6]\ttrain's binary_logloss: 0.116018\ttest's binary_logloss: 0.122999\n",
      "[7]\ttrain's binary_logloss: 0.104074\ttest's binary_logloss: 0.111615\n",
      "[8]\ttrain's binary_logloss: 0.0938035\ttest's binary_logloss: 0.10199\n",
      "[9]\ttrain's binary_logloss: 0.0849435\ttest's binary_logloss: 0.0936671\n",
      "[10]\ttrain's binary_logloss: 0.0765262\ttest's binary_logloss: 0.0858548\n",
      "[Without weight] train binary logloss: 0.0765262104657861, test binary logloss: 0.08585479286835201\n",
      "[With weight] train binary logloss: 0.20111509558258803, test binary logloss: 0.23334695880902565\n",
      "[LightGBM] [Info] Number of positive: 349, number of negative: 3151\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000250 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5100\n",
      "[LightGBM] [Info] Number of data points in the train set: 3500, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499205 -> initscore=-0.003179\n",
      "[LightGBM] [Info] Start training from score -0.003179\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[1]\ttrain's binary_logloss: 0.599823\ttest's binary_logloss: 0.602056\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[2]\ttrain's binary_logloss: 0.5234\ttest's binary_logloss: 0.527533\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[3]\ttrain's binary_logloss: 0.459693\ttest's binary_logloss: 0.465714\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[4]\ttrain's binary_logloss: 0.405868\ttest's binary_logloss: 0.413655\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[5]\ttrain's binary_logloss: 0.359891\ttest's binary_logloss: 0.36924\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[6]\ttrain's binary_logloss: 0.320299\ttest's binary_logloss: 0.331169\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[7]\ttrain's binary_logloss: 0.285977\ttest's binary_logloss: 0.298289\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[8]\ttrain's binary_logloss: 0.256051\ttest's binary_logloss: 0.269504\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[9]\ttrain's binary_logloss: 0.229836\ttest's binary_logloss: 0.244618\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[10]\ttrain's binary_logloss: 0.206785\ttest's binary_logloss: 0.222888\n",
      "[Without weight] train binary logloss: 0.20814183616491222, test binary logloss: 0.21482494425887527\n",
      "[With weight] train binary logloss: 0.20678476665278256, test binary logloss: 0.22288754310582817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "def train_lightgbm(train_X, test_X, train_y, test_y, pos_weight, set_unbalance=True):\n",
    "    params = {\n",
    "        \"num_iterations\": 10,\n",
    "        \"objective\": \"binary\",\n",
    "        \"metrics\": [\"binary_logloss\"],\n",
    "        \"seed\": 0\n",
    "    }\n",
    "    if set_unbalance:\n",
    "        params[\"is_unbalance\"] = True\n",
    "        train_dataset = lightgbm.Dataset(train_X, train_y)\n",
    "        test_dataset = lightgbm.Dataset(test_X, test_y, reference=train_dataset)\n",
    "    else:\n",
    "        train_weights = np.ones_like(train_y)\n",
    "        train_weights[train_y == 1] = pos_weight\n",
    "        test_weights = np.ones_like(test_y)\n",
    "        test_weights[test_y == 1] = pos_weight\n",
    "        train_dataset = lightgbm.Dataset(train_X, train_y, weight=train_weights)\n",
    "        test_dataset= lightgbm.Dataset(test_X, test_y, weight=test_weights, reference=train_dataset)\n",
    "\n",
    "    model = lightgbm.train(params,\n",
    "                           train_dataset,\n",
    "                           valid_sets=[train_dataset, test_dataset],\n",
    "                           valid_names=[\"train\", \"test\"])\n",
    "    train_preds = model.predict(train_X)\n",
    "    test_preds = model.predict(test_X)\n",
    "    print(\"[Without weight] train binary logloss: {}, test binary logloss: {}\".format(log_loss(train_y, train_preds),\n",
    "                                                                     log_loss(test_y, test_preds)))\n",
    "    print(\"[With weight] train binary logloss: {}, test binary logloss: {}\".format(log_loss(train_y, train_preds, pos_weight=pos_weight),\n",
    "                                                                     log_loss(test_y, test_preds, pos_weight=pos_weight)))\n",
    "\n",
    "\n",
    "def main():\n",
    "    X, y = make_classification(5000, weights=[0.9, 0.1], flip_y=0.0, random_state=0)\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "    n_train_pos = train_y.sum()\n",
    "    n_test_pos = test_y.sum()\n",
    "    print(\"Train data, positive: {}, negative: {}, positive ratio: {:.2f}\".format(n_train_pos,\n",
    "                                                                                  len(train_y) - n_train_pos,\n",
    "                                                                                  n_train_pos / len(train_y)))\n",
    "    print(\"Test data, positive: {}, negative: {}, positive ratio: {:.2f}\".format(n_test_pos,\n",
    "                                                                                  len(test_y) - n_test_pos,\n",
    "                                                                                  n_test_pos / len(test_y)))\n",
    "    train_lightgbm(train_X, test_X, train_y, test_y, pos_weight=9, set_unbalance=True)\n",
    "    train_lightgbm(train_X, test_X, train_y, test_y, pos_weight=9, set_unbalance=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
